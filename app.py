# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eCkYU1btuPqPqetfq6nGXMgj5OFKbyDF
"""

# Import Libraries *************************************************************
import pandas as pd
# import numpy as np
import re 
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
stop_words=stopwords.words('english')
from nltk.stem import WordNetLemmatizer
import nltk
from afinn import Afinn
import spacy
# from imblearn.over_sampling import SMOTE
# from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.decomposition import PCA
# from sklearn.svm import SVC
# from pickle import dump
# from pickle import load
# from sklearn.linear_model import LogisticRegression
import streamlit as st
from sklearn.feature_extraction.text import TfidfTransformer
from scipy.sparse import coo_matrix
from spacy.lang.en import English


# Page Setup *************************************************************
st.set_page_config(layout="wide")
# front end elements of the web page
html_temp = """<div style ="background-color:purple;padding:10px"> <h1 style ="color:blue;text-align:center;">Sentiment Analysis for Hotel Review</h1> </div>"""

# display the front end aspect
st.markdown(html_temp, unsafe_allow_html=True)


def add_bg_from_url():
    st.markdown(
         f"""
         <style>
         .stApp {{
             background-image: url("https://wallpapercave.com/wp/wp6957420.jpg");
             background-attachment: fixed;
	     background-position: 25% 75%;
             background-size: cover
         }}
         </style>
         """,
         unsafe_allow_html=True
     )

add_bg_from_url()



# Data Cleaning *************************************************************
#Lemmatization
wordnet=WordNetLemmatizer()

#Stop word
stop_words=stopwords.words('english')

nlp=spacy.load("en_core_web_sm")

# Varibale created for words which are not included in the stopwords
not_stopwords = ("aren", "aren't", "couldn", "couldn't", "didn", "didn't",
                 "doesn", "doesn't", "don", "don't", "hadn", "hadn't", "hasn",
                 "hasn't", "haven", "haven't", "isn", "isn't", "mustn",
                 "mustn't", "no", "not", "only", "shouldn", "shouldn't",
                 "should've", "wasn", "wasn't", "weren", "weren't", "will",
                 "wouldn", "wouldn't", "won't", "very")
stop_words_ = [words for words in stop_words if words not in not_stopwords]

# Additional words added in the stop word list
stop_words_.append("I")
stop_words_.append("the")
stop_words_.append("s")

# Stop word for keyword extraction
stop_words_keywords = stopwords.words('english')

# special additioanl stop words added for keyword extraction
stop_words_keywords.extend([
    "will", "always", "go", "one", "very", "good", "only", "mr", "lot", "two",
    "th", "etc", "don", "due", "didn", "since", "nt", "ms", "ok", "almost",
    "put", "pm", "hyatt", "grand", "till", "add", "let", "hotel", "able",
    "per", "st", "couldn", "yet", "par", "hi", "well", "would", "I", "the",
    "s", "also", "great", "get", "like", "take", "thank"
])

#Pre-processing the new dataset
def processing(corpus):
    output=[]
    
    #convert to string
    review =str(corpus)
    
    #to handle punctuations
    review = re.sub('[^a-zA-Z0-9*]', ' ', review)
    
     # Converting Text to Lower case
    review = review.lower()

    # Spliting each words - eg ['I','was','happy']
    review = review.split()

    # Applying Lemmitization for the words eg: Argument -> Argue - Using Spacy Library
    review = nlp(' '.join(review))
    review = [token.lemma_ for token in review]

    # Removal of stop words
    review = [word for word in review if word not in stop_words_]

    # Joining the words in sentences
    review = ' '.join(review)
    output.append(review)
    
    return output


# Important Attributes *************************************************************
# Important Attributes
def extract_keywords(corpus):
    review = str(corpus)
    review = re.sub('[^a-zA-Z0-9*]', ' ', review)
    review = review.lower()
    review = review.split()
    review = nlp(' '.join(review))
    review = [token.lemma_ for token in review]
    review = [word for word in review if word not in stop_words]
    review = ' '.join(review)
    
    tfidf = TfidfVectorizer(norm="l2", analyzer='word', stop_words=list(stop_words), ngram_range=(1, 2))
    tfidf_x = tfidf.fit_transform([review])
    tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)
    tfidf_transformer.fit(tfidf_x)
    
    feature_names = tfidf.get_feature_names_out()
    tf_idf_vector = tfidf_transformer.transform(tfidf.transform([review]))
    
    def sort_coo(coo_matrix):
        tuples = zip(coo_matrix.col, coo_matrix.data)
        return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)
    
    sorted_items = sort_coo(tf_idf_vector.tocoo())
    
    def extract_topn_from_vector(feature_names, sorted_items, topn=15):
        sorted_items = sorted_items[:topn]
        feature_vals = []
        for idx, score in sorted_items:
            feature_vals.append(feature_names[idx])
        return feature_vals
    
    attributes = extract_topn_from_vector(feature_names, sorted_items, 15)
    return attributes



# Prediction *************************************************************
# following lines create boxes in which user can enter data required to make prediction
# Textbox for text user is entering
st.subheader("Enter the text you'd like to analyze.")
text = st.text_input('Enter text')  # text is stored in this variable

# when 'Button' is clicked, make the prediction and store it  
if st.button("Predict"):
    # predict = Prediction(text)
    cleaned = processing(text)
    afn = Afinn()
    score = [afn.score(item) for item in cleaned]
    Affin_sentiment = ['Positive' if score > 0 else 'Negative' for score in score]
    Reaction = ['ðŸ˜„' if score > 0 else 'ðŸ˜¡' for score in score]
    predict = Affin_sentiment

    st.success('The Sentiment of the review is {} {}'.format(predict, Reaction[0]))
#     st.success('{} score : {}'.format(Reaction[0], score[0]))
    
# if st.button("IMP Attributes"):
    st.subheader("Important Attributes in Reviews")
    imp_att=keywords(text)
    for i in imp_att:
        st.success(i)

